<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>CS 180 Projects</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="CS 180 Projects" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/project-4/" />
<meta property="og:url" content="http://localhost:4000/project-4/" />
<meta property="og:site_name" content="CS 180 Projects" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="CS 180 Projects" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"CS 180 Projects","url":"http://localhost:4000/project-4/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="CS 180 Projects" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">CS 180 Projects</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title"></h1>
  </header>

  <div class="post-content">
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><span style="font-family=Papyrus; font-size:0.8em;"></span></p>

<h2 id="project-4a-image-warping-and-mosaicing">Project 4A: Image Warping and Mosaicing</h2>

<p>In this part of the project, we explored how to warp images using correspondence
points, and also learned how to generate a mosaic “stitch” of images. With this
ability, we are now able to join together images to create a panoramic image. The
most fun part of this project was definitely the image stitching, and it’s still
interesting to think about how my phone camera manages this, since it’s somehow doing
this stitching live.</p>

<h3 id="part-1-shooting-images">Part 1: Shooting Images</h3>

<p>I was doing this project late in the physics building, so I took a couple for this
project:</p>

<p align="center">
  <img src="images/physics-1-resize.jpg" width="300" />
  <img src="images/physics-2-resize.jpg" width="300" />
</p>
<p>These were images I took on my phone, and then rescaled to a smaller size to make the
computation faster.</p>

<p>I also took some using my DSLR camera, shown below:</p>

<h3 id="part-2-computing-homography">Part 2: Computing Homography</h3>

<p>The objective of this section is to explain how we find a homography matrix \(H\)
to match the correspondence points \(p\) to \(p'\) for both images. For this
explanation, we follow Alec Li’s outline in detail. In essence, finding \(H\) boils
down to solving the equation \(p' = Hp\), which can be written out in
vector form as:</p>

\[\begin{bmatrix} a &amp; b &amp; c \\ d &amp; e &amp; f \\ g &amp; h &amp; 1 \end{bmatrix}
\begin{bmatrix} x\\ y\\ 1 \end{bmatrix} = \begin{bmatrix} wx' \\ wy' \\ w'
\end{bmatrix}\]

<p>Solving this system of equations amounts to solving a linear system of equations,
defined by the linear system:</p>

\[\begin{bmatrix} x &amp; y &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; -x x' &amp; -yx'\\ 0 &amp; 0 &amp; 0 &amp; x &amp; y &amp; 1  &amp;
-xy' &amp; -yy' \end{bmatrix}
\begin{bmatrix} a\\ b\\ c\\ d\\ e\\ f\\ g\\ h\end{bmatrix}
= \begin{bmatrix} x' \\ y \end{bmatrix}\]

<p>This system of equations can be solved for each set of pairs \((p, p')\), and we can
solve them in parallel by just stacking the different coordinates to make a bigger
matrix and column vector on the right. One thing to note about this system is that
once 4 points are selected, then the system has an exact solution for \(a, b, ...,
h\). Once more than 4 points are given, then the system becomes <em>overdetermined</em>, and instead of an exact solution we need to use least-squares to find the optimal 
homography matrix \(H\). This method is precisely what the <code class="language-plaintext highlighter-rouge">computeH(im1_pts,
im2_pts)</code> function does.</p>

<h3 id="part-3-warping">Part 3: Warping</h3>

<p>Now that we’ve computed \(H\), we can now move on to performing the actual warp. In
my case, we will have two images <code class="language-plaintext highlighter-rouge">im1</code> and <code class="language-plaintext highlighter-rouge">im2</code>, and I will always be warping 
<code class="language-plaintext highlighter-rouge">im1</code> onto <code class="language-plaintext highlighter-rouge">im2</code>. Similar to the previous project, in order to perform the warp we
just have to apply \(H\) to every pixel in <code class="language-plaintext highlighter-rouge">im1</code>, however this would lead to 
issues because the size of the warped image is almost always larger 
than that of <code class="language-plaintext highlighter-rouge">im1</code>, so if we were to naively just apply \(H\) to <code class="language-plaintext highlighter-rouge">im1</code> 
we will get an undersampled image. Thus, to fix this, we first warp the corners of
<code class="language-plaintext highlighter-rouge">im1</code> to their appropriate locations, which will also define the polygon in which 
the warped <code class="language-plaintext highlighter-rouge">im1</code> will reside in. This inevitably sometimes causes the corners of
<code class="language-plaintext highlighter-rouge">im1</code> to be negative, so to fix this we find the values <code class="language-plaintext highlighter-rouge">x_translate</code> and
<code class="language-plaintext highlighter-rouge">y_translate</code> that are required so that the warped <code class="language-plaintext highlighter-rouge">im1</code> rests perfectly in the 
first quadrant. With the coordinates of the warped <code class="language-plaintext highlighter-rouge">im1</code> determined, we can now
iterate through every point in this polygon and use 
\(H^{-1}\) to compute the corresponding point in <code class="language-plaintext highlighter-rouge">im1</code>
(while also accounting for the translation mentioned just now), then use the same
interpolation procedure we used in the previous project, involving 
<code class="language-plaintext highlighter-rouge">scipy.interpolate.regularGridInterpolator()</code>.</p>

<p>Despite the similarities there are also a couple differences between this 
version of warping and the previous version.
First, notice that the third coordinate of \(Hp\) is not always 1, but in 
order to index into our arrays properly we require that it equals 1, so we need to 
normalize so that \(w = 1\) every time we apply \(H\) or \(H^{-1}\). Another
difference is that in this implementation, I spent a great deal of effort in figuring
out how to vectorize the transformation, so that it can be done much faster. This
ultimately paid off, as it sped up the runtime from ~2 minutes per image to less than 
1 second.</p>

<h4 id="rectification">Rectification</h4>

<p>One application of this warping procedure is that we can now perform a procedure
called <em>rectification</em>, which is the process of perspective transforming a component
in an image into a particular shape. In our case, we will take perspective images of
rectangular objects, then perform the warp such that after warping the image is now
square, or rectified. To do this, we define the correspondence points on the image to 
be rectified as usual, but for the points \(p'\) we wish to map to I instead defined 
a hard-coded set of points <code class="language-plaintext highlighter-rouge">[0, 400], [400, 400], [400, 0], [0, 0]</code>, which forms 
a rectangle. This hard-coding makes sense here, since ultimately all we want to do is
transform the selected points in our <code class="language-plaintext highlighter-rouge">im1</code> into a rectangle. For this part, I took a
photo of my chalk case (hagoromo like project 2!) and also a textbook that was kind
of collecting dust in my home:</p>

<p align="center">
    <img src="images/chalk.jpg" width="200" />
    <img src="images/textbook.jpg" width="400" />
</p>

<p>As an aside, notice the difference in image quality – the textbook I took with my
DSLR, and the chalk case I took with my phone (bad quality by comparison). To compute
the rectification, I selected the following points from both images (marked in red on
the left and yellow on the right):</p>

<p align="center">
    <img src="images/chalk-correspond.png" width="200" />
    <img src="images/textbook-correspond.png" width="400" />
</p>

<p>Correspondingly, here are the rectified images:</p>

<p align="center">
    <img src="images/chalk-rect.png" width="200" />
    <img src="images/textbook-rect.png" width="400" />
</p>

<p>One thing to note with these rectified images is that the more extreme the angle, the
more extreme the resulting warp: it’s clear that the chalk case was shot at a much
shallower angle than the textbook, and as a result the corresponding warp distorts
the upper region much more heavily, to the point where the chalk case almost can’t be
seen. That said, these images are evidence that the rectification procedure does
indeed work, since the resulting objects (the chalk case and the textbook) both
appear square in the final image.</p>

<h4 id="creating-a-mosaic">Creating a Mosaic</h4>

<p>Now, we move on to the final part for part A of this project, which is to join two
images together using our correspondences and stitch the images together. To do this,
I implemented a function <code class="language-plaintext highlighter-rouge">blend(im1, im2, x_translate, y_translate)</code> to do exactly
this.</p>

<p>To implement this function, there are a couple things to consider, the first of which
is the translation. Recall that in morphing <code class="language-plaintext highlighter-rouge">im1</code>, we had to translate it to
guarantee that the resultant image lies in the first quadrant. Because this shift
globally translated every coordinate in <code class="language-plaintext highlighter-rouge">im1</code>, in order for the alignment to be
proper we also need to apply this translation to <code class="language-plaintext highlighter-rouge">im2</code> as well; this is why we have
the arguments <code class="language-plaintext highlighter-rouge">x_translate, y_translate</code> passed into the <code class="language-plaintext highlighter-rouge">blend</code> function.</p>

<p>Next, we need to determine the final size of the canvas, which can be done by taking
the maximum between the shifted <code class="language-plaintext highlighter-rouge">im2</code> and the morphed <code class="language-plaintext highlighter-rouge">im1</code> dimensions. 
Then, for the blending process itself, we do a 2-band Laplacian pyramid (same as what
we did in project 2), blending the
low and high frequency components separately. In the low frequency regime, we take a
distance transformation using <code class="language-plaintext highlighter-rouge">cv2.distanceTransform()</code>, then take a weighted linear
combination of <code class="language-plaintext highlighter-rouge">im1_low</code> and <code class="language-plaintext highlighter-rouge">im2_low</code> (the result of <code class="language-plaintext highlighter-rouge">im1, im2</code> 
after the low-pass filter) to determine the low-frequency component of the stitched
mosaic. The weights are calculated using 
\(\text{weight}_i = \frac{d_i}{d_1 + d_2}\) which is very similar to the 
alpha blending procedure we used in project 2. One thing to note about this weight
procedure is that sometimes it gave me division by zero errors, so I had to
artificially add a very small <code class="language-plaintext highlighter-rouge">1e-5</code> to fix this.</p>

<p>For the high frequency components, the distance transformation alone was used as the
tiebreaker for whether we took the high frequency in <code class="language-plaintext highlighter-rouge">im1</code> or <code class="language-plaintext highlighter-rouge">im2</code> 
for each point. That is, if <code class="language-plaintext highlighter-rouge">dist1</code> has a higher value than <code class="language-plaintext highlighter-rouge">dist2</code> at 
some <code class="language-plaintext highlighter-rouge">[x, y]</code>, then <code class="language-plaintext highlighter-rouge">im1_high[x, y]</code> was taken, and vice versa.</p>

<p>Finally, we add the low and high frequency components together, in the same way we
collapsed the Laplacian stack in Project 2. Taking the images
from the physics building, defining the corresponding points, we can get the
following image stitching:</p>

<p align="center">
    <img src="images/physics-mosaic1.png" width="400" />
</p>

<p>I also took some photos of Physics 251, one of the quiet spots in physics that I like
to go to for studying:</p>

<p align="center">
    <img src="images/physics251-1.JPG" width="300" />
    <img src="images/physics251-2.JPG" width="300" />
</p>

<p>And here’s the stitched image:</p>

<p align="center">
    <img src="images/physics251-mosaic.png" width="400" />
</p>

<p>And another of 251, from a different angle:</p>

<p align="center">
    <img src="images/physics251-4.JPG" width="300" />
    <img src="images/physics251-5.JPG" width="300" />
</p>

<p>Stitched:</p>

<p align="center">
    <img src="images/physics251-mosaic2.png" width="400" />
</p>

<p>Unfortunately, you can’t read the text on that poster, because I downscaled the
image beforehand so that I can use the provided correspondence tool (the image was
too big otherwise). Nonetheless, all three of these images demonstrate evidence of
proper stitching, since we can’t see any seams where the interfaces of the two images
lie.</p>

<p>This last part of the project was incredibly cool to see working: in retrospect, it
the mathematics and procedure make a lot of sense to me, but even after everything I
still think that it’s extremely impressive that we’re able to come up with procedures
to accomplish complex tasks like this – and all it really takes is a little linear
algebra.</p>


  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">CS 180 Projects</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">CS 180 Projects</li><li><a class="u-email" href="mailto:eric.du03@berkeley.edu">eric.du03@berkeley.edu</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
